# Kafka



kafka-server-start.bat config\server.properties

查看topicList ： kafka-topics.bat --list --bootstrap-server localhost:9092
创建生产者： kafka-console-producer.bat --broker-list localhost:9092 --topic topicName
创建消费者： kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic topicName --from beginning



## 教程

## 1.kafka概述

### 1.1 定义

​	kafka是一个分布式的基于发布/订阅模式的消息队列（message queue），主要应用于大数据实时处理领域。

### 1.2 消息队列

##### 1.2.1 传统消息队列的应用场景

![消息队列应用场景](..\img\middleware\kafka\消息队列应用场景.png)



**使用消息队列的好处：**

1.**解耦**

​	允许独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

2.**可恢复性**

​	系统的一部分组件失效时，不会影响整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列的消息仍然可以在系统恢复后被处理。

3.**缓冲**

​	有助于控制和优化数据经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况

4.**灵活性和峰值处理能力**

​	使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

5.**异步通信**

很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但不立即处理它，想向队列中放入多少消息就放入多少，然后在需要的时候再去处理。

##### 1.2.2 消息队列的两种形式

1. **点对点模式(一对一，消费者主动拉取数据，消息收到后消息清除)**

   消息生产者生产消息发送到Queue中，然后消费者从Queue中取出并消费消息。消息被消费以后，Queue中不再存储，所以消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但对于一个消息而言，只有一个消费者可以消费。

   ![image-20231014163119969](..\img\middleware\kafka\点对点.png)

2. **发布、订阅模式（一对多，消费者消费消息之后不会清除消息）**

   消息生产者（发布）将消息发布到topic中，同事有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic中的消息会被所有订阅者消费。

![image-20231014164311262](..\img\middleware\kafka\发布订阅.png)



### 1.3 kafka基础架构

![image-20231014164400065](..\img\middleware\kafka\kafka架构.png)

**1. Producer**

​	消息生产者，就是向kafka broker发消息的客户端

**2.Consumer**

​	消息消费者，向kafka broker取消息的客户端

**3.Consumer** **Group**

​	消费者组，由多个Consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内的消费者消费；消费者组间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。

**4.Broker**

​	一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic

**5.topic**

​	可以理解为一个队列，生产者和消费者面向都是一个topic

**6.Partition**

​	为了实现拓展性，一个非常大的topic可以分不到多个broker上，一个topic可以分为多个partition，每个partition都是一个有序的队列。

**7.Replication**

​	副本，为保证集群中某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然可以继续工作，kafka提供了副本控制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。

**8.leader**

​	每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据时的对象都是leader。

**9.follower**

​	每个分区多个副本的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader。



## 2.Kafka 的安装

### 2.1 安装地址

[Kafka 官网](https://kafka.apache.org/)

### 2.2 安装流程

1. 将下载好的安装包上传到 Linux 服务器。（我这里使用的是 kafka_2.11-0.11.0.0.tgz）
   2. 解压安装包到指定目录。

```shell
tar -zxvf kafka_2.11-0.11.0.0.tgz -C /opt/module/
```

3. 修改解压后的文件名称。

```shell
mv kafka_2.11-0.11.0.0/ kafka
```

4. 在 /opt/module/kafka 目录下创建 logs 文件夹。

```shell
mkdir logs
```

5. 修改 config 目录下的配置文件 server.properties。
   输入以下内容：

```shell
#broker 的全局唯一编号，不能重复
broker.id=0
#删除 topic 功能使能
delete.topic.enable=true
#处理网络请求的线程数量
num.network.threads=3
#用来处理磁盘 IO 的现成数量
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
#接收套接字的缓冲区大小
socket.receive.buffer.bytes=102400
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600
#kafka 运行日志存放的路径
log.dirs=/opt/module/kafka/data
#topic 在当前 broker 上的分区个数
num.partitions=1
#用来恢复和清理 data 下数据的线程数量
num.recovery.threads.per.data.dir=1
#segment 文件保留的最长时间，超时将被删除
log.retention.hours=168
#配置连接 Zookeeper 集群地址
zookeeper.connect=master:2181,slave1:2181,slave2:2181
```

6. 将 kafka 目录分发到另外两台机器上。
   ```shell
   scp kafka/ master:/opt/module/
   
   scp kafka/ slave2:/opt/module/
   
   ```

   7. 在另外两台机器上修改配置文件 /opt/module/kafka/config/server.properties 中的 broker.id=1、broker.id=2（broker.id 不得重复）

8. 配置环境变量。

```shell
vim /etc/profile
```


添加以下内容：

```shell
#KAFKA_HOME
export KAFKA_HOME=/opt/module/kafka
export PATH=$PATH:$KAFKA_HOME/bin

```

让配置文件生效：

 ```she
 source /etc/profile
 ```

在另外两台机器做以上操作。

9. 启动集群。

依次在 master、slave1、slave2 节点上启动 Kafka。

```she
kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties
```

10. 关闭集群。

依次在 master、slave1、slave2 节点上关闭 Kafka。

```she
kafka-server-stop.sh stop
```

11. 在 /opt/module/kafka/bin 目录下编写群起群关脚本 kk.sh，方便以后使用。
    ```she
    vim kk.sh
    ```


    ```shell
    11. #!/bin/bash
    
    case $1 in
    "start"){
      for i in master slave1 slave2
        do
          echo "****************** $i *********************"
          ssh $i "source /etc/profile && /opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"
        done
    };;
    
    "stop"){
      for i in master slave1 slave2
        do
          echo "****************** $i *********************"
          ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh"
        done
    };;
    
    esac
    ```

    ```she
    chmod 777 kk.sh
    ```


    ![image-20231014171320208](..\img\middleware\kafka\演示截图1.png)
    

说明：kafka集群关闭时会需要一些时间



### 2.3 Kafka 命令行操作

1. 创建 topic。

```shell
kafka-topics.sh --zookeeper slave1:2181 --create --replication-factor 3 --partitions 2 --topic demo
```

![image-20231014171506569](..\img\middleware\kafka\创建topic.png)

2. 查看当前服务器中所有的 topic。
   ```shell
   kafka-topics.sh --zookeeper slave1:2181 --list
   ```

   ![image-20231014171547419](..\img\middleware\kafka\查看topic.png)

3. 查看某个 topic 的详情。
   ```shell
   kafka-topics.sh --zookeeper slave1:2181 --describe --topic demo
   ```

   ![image-20231014171722107](..\img\middleware\kafka\查看某个topic详情.png)

4. 删除 topic。
   ```shell
   kafka-topics.sh --zookeeper slave1:2181 --delete --topic first
   ```

   ![image-20231014171804977](..\img\middleware\kafka\删除topic.png)

5. 发送消息。
   ```shell
   kafka-console-producer.sh --broker-list slave1:9092 --topic demo
   ```

   ![image-20231014171831137](..\img\middleware\kafka\发送消息.png)

6. 消费消息。
   （1）方法一

```shell
 kafka-console-consumer.sh --zookeeper slave1:2181 --topic demo
```

![image-20231014171929258](..\img\middleware\kafka\消费消息1.png)

注意： 该方法已经过时。

（2）方法二

```shell
kafka-console-consumer.sh --bootstrap-server slave1:9092 --topic demo
```

![image-20231014171900273](..\img\middleware\kafka\消费消息2.png)

说明： 在以上两种方法的命令上添加 –from-beginning 参数会把主题中以往所有的数据都读取出来。



## 3. kafka 架构深入理解

### 3.1 kafka工作流程

![image-20231014172059009](..\img\middleware\kafka\kafka工作流程.png)



​	kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。topic是逻辑上的概念。而partition是物理上的概念，每个partition对应一个log文件，该文件存储的就是producer生产的数据。producer生产的数据会不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。

### 3.2 kafka 文件存储机制

![image-20231014205312019](..\img\middleware\kafka\文件存储机制.png)



​	由于生产者生产的消息不断追加到log文件末端，为防止log文件过大导致数据定位效率低下，kafka采取了分片和索引机制，将每个partition分为多个segment。每个segment对应两个文件，“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹命名规则为：topic名称+分区序号。例如demo这个topic有两个分区，则其对应的文件夹为demo-0，demo-1.

![image-20231014205821517](..\img\middleware\kafka\image-20231014205821517.png)



"index"文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。



### 3.3 kafka生产者

##### 3.3.1 分区策略

1. 分区的原因

   （1）方柏霓在集群中扩展，每个partition可以通过调整以适应他们的机器，而一个topic又可以有多个partition组成，因此整个集群就可以适应任意大小的数据了。

   （2）可以提高并发，因为可以以partition为单位读写。

2. 分区的原则

   我们需要将producer发送的数据封装成一个producerRecord对象

   ![image-20231014210603611](..\img\middleware\kafka\发送方法.png)

​		(1) 指明partition的情况下，直接将指明的值作为partition值；

​		(2）没有指明partition值但有key的情况下，将key值与topic的partition数进行取余得到partition值；

​		(3)  既没有partition又没有key值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与topic可用的partition总数取余得到partition值，也就是常说的round-robin（轮询）算法。

##### 3.3.2 数据可靠性保证

​		为保证producer发送的数据，能可靠的发送到指定的topic，topic中的每个partition收到producer发送的数据后，都需要producer发送ack，如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。

![image-20231014211732317](..\img\middleware\kafka\数据可靠性保证.png)

1. **副本同步策略**

   | 方案                        | 优点                                               | 缺点                                                |
   | --------------------------- | -------------------------------------------------- | --------------------------------------------------- |
   | 半数以上完成同步，就发送ack | 延迟低                                             | 选取新的leader时，容忍n台节点的故障，需要2n+1个副本 |
   | 全部完成同步，就发送ack     | 选取新的leader时，容忍n台节点的故障，需要n+1个副本 | 延迟高                                              |

   kafka采用的是第二种方案。因为第一种方案会造成大量数据的冗余，虽然第二种方案的网络延迟会比较高，但网络延迟对kafka的影响较小。

2.  **ISR**

   ​	kafka采用第二种方案后，可能会出现一个问题：leader收到数据后，所有的follower都开始同步数据，但当某个follower因为故障，迟迟不能与leader进行同步，那么leader就要一直等下去，直到它完成同步，才能发送ack。

   ​	为了解决这个问题，leader维护了一个动态的in-sync replica（ISR），意味着和leader保持同步的follower集合。当ISR中的follower完成数据同步后，leader就会给producer发送ack。如果follower长时间未向leader同步数据，则该follower将被提出ISR，该时间阈值由replica.log.time.max.ms参数设定。leader发生故障后，就会从ISR中选取新的leader。

3.  **ack应答机制**

​			对于某些不太重要数据，对数据的可靠性要求不是很高，能够容忍少量的数据丢失，所以没必要等ISR中所有follower全部接收成功。

​			kafka为用户提供了三种可靠性级别。

​																acks参数配置

| acks参数取值 | 说明                                                         |
| ------------ | ------------------------------------------------------------ |
| 0            | producer不等待broker的ack，这一操作提供一个最低延迟，broker-接收还没有写入磁盘就已经返回，当broker故障时可能丢失数据。 |
| 1            | producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步之前，leader故障，那么将会丢失数据 |
| -1           | producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack，但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。 |



4.**故障处理细节**

![image-20231014214227505](..\img\middleware\kafka\故障处理细节.png)

**LEO**: 指的是每个副本最大的offset。

**HW**：指的是消费者能见到的最大的offset，ISR队列中最小的LEO



​	（1）**follower故障**

​				follower发生故障之后会被临时踢出ISR，待follower恢复之后，follower会读取本地磁盘记录上次的HW，并将log文件高于HW的部分裁掉，从HW开始向leader进行同步。等待followers的LEO大于等于该partition的HW，即follower追上leader之后，就可以重新加入ISR了。

​	（2）**leader故障**

​				leader发生故障后，会从ISR中选出一个新的leader，之后为保证多个副本间的数据一致性，其余的 follower 会先将各自的 log 文件高出 HW 的部分裁掉，然后从新的 leader 同步数据。































































**面试题总结**：

**1、简单描述一下kafka的特点**
Kafka 与周边生态系统的兼容性是最好的没有之一，设计上大量使用了批量和异步的思想，这种设计使得 Kafka 能做到超高的性能（大约每秒钟可以处理几十万条消息）

> Kafka 这种异步批量的设计带来的问题是，它的同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送。
> 业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合在线业务场景。

**2、kafka的主要作用有什么？**
（1）异步处理
（2）流量控制
（3）服务解耦

**3、kafka引入了什么问题？**
（1）异步处理带来了延迟的问题
（2）增加了系统的复杂度
（3）可能产生数据不一致的情况

**4、一个好的消息队列应该具备什么？**
（1）开源并且又良好的活跃度和社区氛围
（2）消息可靠传递（可靠性）
（3）支持集群（高可用）
（4）性能好（高性能）

## 消息队列模型

**1、消息队列的消息模型有哪些？**
（1）单队列模型：所有生产者把生产的消息都写入到同一个队列中，所有的消费者都竞争同一个队列中的消息，也就是说一份消息只能被一个消费者消费，不可被多个消费者多次消费。
（2）多队列模型：生产者把同一个消息写入到多个队列中，每个消费者只从一个队列中消费消息，解决了单队列模型中一条消息不可被多次消费的问题。引入的新问题是，多队列模型下生产者必须知道下游有多好个消费者需要消费它的消息，相当于没有实现消息队列服务解耦的功能。
（3）发布/订阅模型：发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。“订阅”在这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。

> 在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 kafka 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，我们在使用消息队列的时候，丢消息的原因大多是由于消费位置处理不当导致的。

**2、简单聊聊消息队列中的请求-确认机制**
消息队列产品都使用一种非常朴素的“请求 - 确认”机制，确保消息不会在传递过程中由于网络或服务器故障丢失。

生产端：生产者先将消息发送给服务端，也就是 Broker，服务端在收到消息并将消息写入主题或者队列中后，会给生产者发送确认的响应。如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；

消费端：消费者在收到消息并完成自己的消费业务逻辑后，也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。

**3、请求-确认机制会带来什么问题？**
为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则就会出现消息空洞，违背了有序性这个原则。也就是说，每个主题在任意时刻，至多只能有一个消费者实例在进行消费，那就没法通过水平扩展消费者的数量来提升消费端总体的消费性能。

为了解决上述的问题，在主题下新增了【分区】的概念，每个主题包含多个【分区】，通过多个【分区】来实现多实例并行生产和消费。只保证消息在【分区】上的有序性，主题层面无法保证消息的严格顺序。

> 订阅者的概念是通过消费组来体现。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响。消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。如果一条消息被消费者 Consumer1 消费了，那同组的其他消费者就不会再收到这条消息。

## 分布式事务

**1、举例说明什么是分布式事务**
创建订单与从购物车删除已下单商品两个操作，因为从购物车删除已下单商品这个步骤，并不是用户下单支付这个主要流程中必需的步骤，使用消息队列来异步清理购物车是更加合理的设计。

如果本地的订单没有创建成功，但是发出去的删除购物车中商品的消息已经被消费处理了，这就是一个分布式事务。

> 创建订单和发送消息这两个步骤要么都操作成功，要么都操作失败，不允许一个成功而另一个失败的情况出现，这就是消息队列分布式事务需要解决的问题了。

**2、分布式事务有什么局限性？**
对于分布式系统来说，严格的实现 ACID 这四个特性几乎是不可能的，或者说实现的代价太大，大到我们无法接受。

分布式事务就是要在分布式系统中的实现事务。在分布式系统中，在保证可用性和不严重牺牲性能的前提下，光是要实现数据的一致性就已经非常困难了，所以出现了很多“残血版”的一致性，比如顺序一致性、最终一致性等等。

**3、消息队列是怎么实现分布式事务的？**
（1）订单系统在消息队列上开启一个事务
（2）订单系统给消息服务器发送一个“半消息”

> 半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。

（3）订单系统就可以执行本地事务了

> 在订单库中创建一条订单记录，并提交订单库的数据库事务。

（4）根据本地事务的执行结果决定提交或者回滚事务消息

> 订单创建成功，那就提交事务消息，购物车系统就可以消费到这条消息继续后续的流程
> 订单创建失败，那就回滚事务消息，购物车系统就不会收到这条消息。

**4、半消息实现的分布式事务存在什么问题？消息队列都是怎么解决的？**
存在的问题是，本地事务执行成功，但是分布式事务却提交失败了，那么也会导致数据不一致的问题。

kafka解决方案：直接抛出异常，让用户自行处理。我们可以在业务代码中反复重试提交，直到提交成功，或者删除之

RocketMQ解决方案：增加了事务反查的机制来解决事务消息提交失败的问题。如果 Producer 也就是订单系统，在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer 上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。

**5、kafka的事务实现流程**
（1）开启事务的时候，生产者会给协调者发一个请求来开启事务，协调者在事务日志中记录下事务 ID。
（2）生产者在发送消息之前，还要给协调者发送请求，告知发送的消息属于哪个主题和分区，这个信息也会被协调者记录在事务日志中。
（3）生产者就可以像发送普通消息一样来发送事务消息
（4）消息发送完成后，生产者给协调者发送提交或回滚事务的请求，由协调者来开始两阶段提交，完成事务。

> 第一阶段：协调者把事务的状态设置为“预提交”，并写入事务日志。到这里，实际上事务已经成功了，无论接下来发生什么情况，事务最终都会被提交。
> 第二阶段：协调者在事务相关的所有分区中，都会写一条“事务结束”的特殊消息，当 Kafka 的消费者，也就是客户端，读到这个事务结束的特殊消息之后，它就可以把之前暂时过滤的那些未提交的事务消息，放行给业务代码进行消费了。

（5）最后，协调者记录最后一条事务日志，标识这个事务已经结束了。

## 消息队列消息

**1、消息队列怎么检查是否丢失了消息？**
Producer 端，我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。

消息队列的客户端都支持拦截器机制，你可以利用这个拦截器机制，在 Producer 发送消息之前的拦截器中将序号注入到消息中，在 Consumer 收到消息的拦截器中检测序号的连续性，这样实现的好处是消息检测的代码不会侵入到你的业务代码中，待你的系统稳定后，也方便将这部分检测的逻辑关闭或者删除。

> 有一下要点需要注意：
> （1）Kafka 和 RocketMQ 这样的消息队列，它是不保证在 Topic 上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。
> （2）系统中 Producer 是多实例的，由于并不好协调多个 Producer 之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。
> （3）Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。

**2、消息队列如何保证不丢消息**
生产者：
最常用的请求确认机制，来保证消息的可靠传递，只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。

broker：
（1）单节点情况下，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。
（2）集群情况下：需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失。

消费者：
编写消费代码时需要注意的是，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。

**3、消息队列中产生的重复消息怎么处理？**
消息队列中普遍使用At least one + 幂等性的方式去保证重复消息不会对业务产生影响。

> MQTT 三种传递消息时能够提供的服务质量标准
> （1）At most once：消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。
> (2) At least once：消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。
> （3）Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。

**4、幂等性的实现方式有什么哪些？**
（1）利用数据库的唯一约束实现幂等
（2）乐观锁

> 为更新的数据设置前置条件，给你的数据增加一个版本号属性，每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新。

（3）记录并检查操作

> 在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。这种方式是通用性最高的，但是存在以下的问题：
> （a）每个消息指定一个全局唯一的 ID 就是一件不那么简单的事儿，方法有很多，但都不太好同时满足简单、高可用和高性能，或多或少都要有些牺牲。
> （b）检查消费状态 —> 更新数据 —> 设置消费状态，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug。

**5、导致消息堆积的原因可能是什么？**
（1）生产者发送变快了
（2）消费者消费变慢了
（3）消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。

**6、对于消息堆压有什么优化的方案？**
在使用消息队列的系统中，对于性能的优化，主要体现在生产者和消费者这一收一发两部分的业务逻辑中。

发送端优化：
（1）一般发送端都是先执行自己的业务逻辑，最后再发送消息。如果说，你的代码发送消息的性能上不去，你需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的。
（2）对于发送消息的业务逻辑，只需要注意设置合适的并发和批量大小，就可以达到很好的发送性能。

> 无论是增加每次发送消息的批量大小，还是增加并发，都能成倍地提升发送性能。至于到底是选择批量发送还是增加并发，主要取决于发送端程序的业务性质。简单来说，只要能够满足你的性能要求，怎么实现方便就怎么实现。

消费端优化：
（1）优化消费业务逻辑
（2）水平扩容，增加消费端的并发数来提升总体的消费性能

> 在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。原因我们之前讲过，因为对于消费者来说，在每个分区上实际上只能支持单线程消费。

消费端优化有一个错误的例子：
消息处理的业务逻辑可能比较慢，也很难再优化了，为了避免消息积压，在收到消息的 OnMessage 方法中，不处理任何业务逻辑，把这个消息放到一个内存队列（我们语言标准库中的一个队列）里面就返回了。然后它可以启动很多的业务线程，这些业务线程里面是真正处理消息的业务逻辑，这些线程从内存队列里取消息处理，这样它就解决了单个 Consumer 不能并行消费的问题。

这个方案的问题是：会丢消息。如果收消息的节点发生宕机，在内存队列中还没来及处理的这些消息就会丢失。

## 消息队列高性能

**1、消息队列都有哪些高性能的设计**
（1）异步设计
（2）消息批处理
（3）基于磁盘文件高性能顺序读写的特性来设计的存储结构
（4）利用操作系统的 PageCache 来缓存数据，减少 IO 并提升读性能
（5）使用零拷贝技术加速消费流程

**2、描述一下消息队列的异步设计**
异步是一种程序设计的思想，使用异步模式设计的程序可以显著减少线程等待，从而在高吞吐量的场景中，极大提升系统的整体性能，显著降低时延。因此，像消息队列这种需要超高吞吐量和超低时延的中间件系统，在其核心流程中，一定会大量采用异步的设计思想。

> 举例说明：
> 在这种实现中，每处理一个请求需要耗时 100ms，并在这 100ms 过程中是需要独占一个线程的，那么可以得出这样一个结论：每个线程每秒钟最多可以处理 10 个请求。我们知道，每台计算机上的线程资源并不是无限的，假设我们使用的服务器同时打开的线程数量上限是 10,000，可以计算出这台服务器每秒钟可以处理的请求上限是： 10,000 （个线程）* 10（次请求每秒） = 100,000 次每秒。
>
> 如果请求速度超过这个值，那么请求就不能被马上处理，只能阻塞或者排队，这时候 Transfer 服务的响应时延由 100ms 延长到了：排队的等待时延 + 处理时延 (100ms)。也就是说，在大量请求的情况下，我们的微服务的平均响应时延变长了。
>
> 这是不是已经到了这台服务器所能承受的极限了呢？其实远远没有，如果我们监测一下服务器的各项指标，会发现无论是 CPU、内存，还是网卡流量或者是磁盘的 IO 都空闲的很，我们服务中的那 10,000 个线程在干什么呢？对，绝大部分线程都在同步等待服务返回结果。

异步设计由于流程的时序和同步实现是一样，在低请求数量的场景下，平均响应时延一样是 100ms。在超高请求数量场景下，异步的实现不再需要线程等待执行结果，只需要个位数量的线程，即可实现同步场景大量线程一样的吞吐量。

由于没有了线程的数量的限制，总体吞吐量上限会大大超过同步实现，并且在服务器 CPU、网络带宽资源达到极限之前，响应时延不会随着请求数量增加而显著升高，几乎可以一直保持约 100ms 的平均响应时延。

**3、消息队列中使用的IO模型是什么？**
使用了IO多路复用的模型，只用少量的线程就能处理大量的连接，有数据到来的时候能第一时间处理就可以了。

> Selecor 通过一种类似于事件的机制来解决这个问题。首先你需要把你的连接，也就是 Channel 绑定到 Selector 上，然后你可以在接收数据的线程来调用 Selector.select() 方法来等待数据到来。这个 select 方法是一个阻塞方法，这个线程会一直卡在这儿，直到这些 Channel 中的任意一个有数据到来，就会结束等待返回数据。它的返回值是一个迭代器，你可以从这个迭代器里面获取所有 Channel 收到的数据，然后来执行你的数据接收的业务逻辑。你可以选择直接在这个线程里面来执行接收数据的业务逻辑，也可以将任务分发给其他的线程来执行，如何选择完全可以由你的代码来控制。

**4、什么情况下消息队列适合使用数据压缩？**
压缩它的本质是资源的置换，是一个时间换空间，或者说是 CPU 资源换存储资源的游戏。

压缩和解压的操作都是计算密集型的操作，非常耗费 CPU 资源。如果你的应用处理业务逻辑就需要耗费大量的 CPU 资源，就不太适合再进行压缩和解压。

如果你的系统的瓶颈是磁盘的 IO 性能，CPU 资源又很闲，这种情况就非常适合在把数据写入磁盘前先进行压缩。

> Kafka 是否开启压缩是一个可配置的项，并且可以配置使用哪种压缩算法，如果生产者和消费者的 CPU 资源不是特别吃紧，开启压缩后，可以节省网络带宽和服务端的存储空间，提升总体的吞吐量，一般都是个不错的选择。

## 消息队列内存管理

**1、消息队列的内存分配流程**
（1）计算要创建对象所需要占用的内存大小
（2）在内存中找一块儿连续并且是空闲的内存空间，标记为已占用；
（3）把申请的内存地址绑定到对象的引用上，这时候对象就可以使用了。

**2、在高并发情况下进程为什么会卡死？**
高并发的情况下，我们的程序会非常繁忙，短时间内就会创建大量的对象，这些对象将会迅速占满内存，这时候，由于没有内存可以使用了，垃圾回收被迫开始启动，并且，这次被迫执行的垃圾回收面临的是占满整个内存的海量对象，它执行的时间也会比较长，相应的，这个回收过程会导致进程长时间暂停。

进程长时间暂停，又会导致大量的请求积压等待处理，垃圾回收刚刚结束，更多的请求立刻涌进来，迅速占满内存，再次被迫执行垃圾回收，进入了一个恶性循环。如果垃圾回收的速度跟不上创建对象的速度，还可能会产生内存溢出的现象。

> 解决方案：
> （1）尽量少使用一次性的对象
> （2）使用对象池来管理占用内存大的一次性对象
> （3）使用更大内存的服务器

**3、消息队列的缓存策略是什么？**
kafka采用了读写缓存策略，也就是说应用程序在写文件的时候，操作系统会先把数据写入到 PageCache 中，数据在成功写到 PageCache 之后，对于用户代码来说，写入就结束了。然后，操作系统再异步地把数据更新到磁盘的文件中。

> 这种缓存的方式存在一个问题：
> 在数据写到 PageCache 中后，它并不是同时就写到磁盘上了，这中间是有一个延迟的。操作系统可以保证，即使是应用程序意外退出了，操作系统也会把这部分数据同步到磁盘上。但是，如果服务器突然掉电了，这部分数据就丢失了。

**4、既然读写缓存的方式存在缺点，为什么kafka还是采用了呢？**
（1）消息队列它的读写比例大致是 1：1，因为，大部分我们用消息队列都是一收一发这样使用。这种读写比例，只读缓存既无法给写加速，读的加速效果也有限，并不能提升多少性能。
（2）Kafka 它并不是只靠磁盘来保证数据的可靠性，它更依赖的是，在不同节点上的多副本来解决数据可靠性问题，这样即使某个服务器掉电丢失一部分文件内容，它也可以从其他节点上找到正确的数据，不会丢消息。
（3）PageCache 这个读写缓存是操作系统实现的，Kafka 只要按照正确的姿势来使用就好了，不涉及到实现复杂度的问题。

**5、我们如何去保证缓存的数据新鲜？**
（1）更新磁盘数据的同时更新缓存数据
（2）定时将磁盘上的数据同步到缓存中
（3）不去更新缓存中的数据，而是给缓存中的每条数据设置一个比较短的过期时间

## 消息队列集群管理

**1、主从模式下的主节点选举方案有哪些？**
（1）使用一个第三方的管理服务
优点：选举速度快，主节点宕机造成的不可用时间短
缺点：管理服务本身的高可用、数据一致性难以保证
（2）消息队列选择自选举的方式
优点：没有外部依赖，可以实现自我管理
缺点：投票的实现都比较复杂，并且选举的过程是比较慢的，几秒至几十秒都有可能，在选出新的主节点前，服务一直是不可用的。

**2、消息复制的基本单位是什么？**
Kafka 中，复制的基本单位是分区。每个分区的几个副本之间，构成一个小的复制集群，Broker 只是这些分区副本的容器，所以 Kafka 的 Broker 是不分主从的。

分区的多个副本中也是采用一主多从的方式。Kafka 在写入消息的时候，采用的也是异步复制的方式。消息在写入到主节点之后，并不会马上返回写入成功，而是等待足够多的节点都复制成功后再返回。在 Kafka 中这个“足够多”是多少呢？Kafka 的设计哲学是，让用户自己来决定。

> Kafka 为这个“足够多”创造了一个专有名词：ISR（In Sync Replicas)，翻译过来就是“保持数据同步的副本”。ISR 的数量是可配的，但需要注意的是，这个 ISR 中是包含主节点的。

**3、如何选择消息复制的个数？**
大部分复制的实现，都不会选择把消息写入全部副本再返回确认，因为这样虽然可以保证数据一致性，但是，一旦这些副本中有任何一个副本宕机，写入就会卡死了。如果只把消息写入到一部分副本就认为写入成功并返回确认，就可以解决卡死的问题，并且性能也会比写全部副本好很多。

> 举例说明：
> 假设我们的集群采用“一主二从三副本”的模式，如果只要消息写入到两个副本就算是写入成功了，那这三个节点最多允许宕机一个节点，否则就没法提供服务了。
> 如果说我们把要求写入的副本数量降到 1，只要消息写入到主节点就算成功了，那三个节点中，可以允许宕机两个节点，系统依然可以提供服务，这个可用性就更好一些。（主节点有一部分消息还没来得复制到任何一个从节点上，主节点就宕机了，这时候就会丢消息，数据一致性又没有办法保证了。）

根据示例你可以看出，这里面是有很多天然的矛盾，所以，目前并没有一种完美的实现方案能够兼顾高性能、高可用和一致性。

**4、客户端找集群中正确节点？**
生产者启动流程时提到过，生产者只要配置一个接入地址，就可以访问整个集群，并不需要客户端配置每个 Broker 的地址。Kafka 会自动根据要访问的主题名称和队列序号，找到对应的 Broker 地址。如果 Broker 发生宕机，客户端还会自动切换到新的 Broker 节点上，这些对于用户代码来说都是透明的。这些功能都是由 NameServer 协调 Broker 和客户端共同实现的，其中 NameServer 的作用是最关键的。

kafka通过zookeeper实现了NameServer的功能，通过zookeeper本身具有分布式存储的特点，对主题/分区对应的broker信息进行了存储。客户端并不直接和 ZooKeeper 来通信，而是在需要的时候，通过 RPC 请求去 Broker 上拉取它关心的主题的元数据，然后保存到客户端的元数据缓存中，以便支撑客户端生产和消费