juc

redis=》 22

mysql

jvm

austin流程



### redis

##### redis是什么？

redis是一种基于key-value存储的非关系型数据库；

支持多种数据结构 string（token，计数），hash（用户信息），list（列表），set（共同关注），zset（排行榜）

基于内存，而且是单线程，避免了线程切换，所以读写速度非常出色

redis还提供了键过期，事务（multi开启事务，exec执行），lua脚本等功能

redis还提供了将内存中的数据利用快照或日志保存到磁盘，防止断电后数据丢失



##### redis多路复用

以epoll为例：

将用户socket对应的id都注册到epoll中，然后epoll监听哪个socket上有消息到达，然后就处理哪个，充分利用资源



##### 持久化

rdb 和 aof

rdb：redis data base 是把当前进程中的数据生成快照存放到硬盘，以便重启时恢复数据

两种方式：手动 自动；；手动触发分为save命令 阻塞当前服务器，直到rdb完成，对于比较大的实例，可能会阻塞较长时间

bgsave，fork个子进程，在子进程中完成rdb，阻塞只在fork的一瞬间。

自动触发：shutdown如果没有开启aof会触发 ， save m n m秒内修改n次触发；



rdb是一个紧凑的二进制文件，数据恢复速度快，但由于间隔一段时间持久化，所以可能会损失一段时间的数据。



aof（append only file），以独立日志的方式记录每次写命令，再次重启时重新执行命令以达到恢复数据的目的。

aof解决了数据持久化的实时性问题，但是文件较大，恢复数据速度慢。

流程：文件写入=》同步=》重写=》



选择：一般来说会选择混合的方式进行持久化，如果可以容忍一段时间数据的丢失，可以选择rdb

全量的rdb和增量的aof日志文件。



##### 高可用

主从复制，哨兵，集群

主从复制：数据冗余，故障恢复，负载均衡，高可用基石

一主一从；故障转移

一主多从：读写分离

问题：一旦主节点出现故障，需要手动将从节点升级为主节点



##### 哨兵

作用：监控，自动故障转移，配置提供者，通知

主观下线和客观下线：主观：每个sentinel每秒会向其他主节点，从节点，sentinel节点发送ping命令，如果超过规定的时间没有回复，则认为失败下线

客观：当下线的是主节点时，从节点会向其他从节点发送命令询问，如果多数从节点都判断主节点下线，那就做出客观下线的决定



故障转移流程：

1.选举出一个主节点

2.执行命令slaveof no one让其成为主节点

3.主节点向剩余的从节点发送命令，让其成为新主节点的从节点

4.将原来的主节点更新为从节点，待其故障恢复后，复制新的主节点



sentinel选举：每个在线的sentinel节点都有资格成为领导者，当他确定主节点下线时，会向其他sentinel节点发送命令，如果其他sentinel没有同意

其他sentinel节点，就不会拒绝，如果得到票数大于规定票数，那么他会成为领导者，否则进入下一次选举。



新节点：过滤不健康的节点（主观下线，断线），，选择从节点最高的从节点列表，存在返回不存在继续，，选择复制偏移量最大的从节点（数据最完整），，选择runid最小的从节点。



redis集群：解决高可用和分布式的问题

数据分区：节点取余分区，一致性hash分区，虚拟槽分区



##### 缓存

缓存击穿：key过期，直接访问数据库++++++++解决：加锁更新，把过期时间写进value，异步更新

缓存穿透：缓存数据库都不存在++++++++解决：缓存空值默认值；设置较短的过期时间，布隆过滤器

缓存雪崩：同一时间大量的key过期，全部访问数据库++++++++解决：均匀的设置过期时间，集群，热点数据永不过期



缓存数据库一致性：

删除缓存还是更新缓存：删除缓存++删除缓存操作更快，redis以空间换时间，更新缓存可能一段时间用不到，造成一段时间的数据冗余

先更新数据库还是先删除缓存：先更新数据库++更新数据库的操作设计锁行锁表操作，几乎不可能在删除缓存之前完成

消息队列：更新数据库后，发送消息到消息队列，待消费消息成功后，删除缓存

canal+mq，使用阿里的数据库监听中间件监听binlog变化，一旦数据修改，canal会自动发送消息到消息队列



布隆过滤器：是一个连续的数据结构，每个存储位存储一个bit位存储0或1，判断key是否存在即判断是否全是1



本地缓存和分布式缓存的一致性问题：本地缓存Caffeine，分布式缓存redis，，可以使用redis的发布订阅，，也可以使用消息队列



缓存预热：

1.写个接口，上线后手动更新

2.数据量不大的情况下，项目启动时更新

3.定时刷新



热key问题：热key通常大量的访问，首先监控，每次调用redis，对key进行记录

也可以使用命令查看每个key的调用次数 monitor命令

监控到之后：把热key打散到不同的服务器，加入二级缓存，每次先从二级缓存查询



热key重建：开发的时候一般使用“缓存+过期时间”的策略，既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求

但是可能并发量大，涉及大量的计算，短时间重建不好

解决：1.互斥锁，只允许一个线程重建，，2.永不过期，对每个值设置一个过期值



无底洞问题：节点不断增加，性能反而下降

先分析一下无底洞问题：

- 客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着节点的增多，耗时会不断增大。
- 网络连接数变多，对节点的性能也有一定影响。

常见的优化思路如下：

- 命令本身的优化，例如优化操作语句等。
- 减少网络通信次数。
- 降低接入成本，例如客户端使用长连/连接池、NIO等。



#####  redis运维

redis内存不足：修改配置文件的maxmemory，，集群部署

redis过期回收策略： 定时删除：创建key时，增加过期时间，，当过期key较多时，会占用大量的cpu

​									 惰性删除：查询key的时候进行检查，如果key一直没有被查询，那就永远不会删除

​									 定期删除：每隔一段时间对数据库做一次检查，删除过期的key，，由于不可能对所有的key做轮询，所以随机取一些key检查

redis使用惰性+定期：：先定期删除，由于随机取key，所以没有取到的key惰性删除



内存溢出/内存淘汰策略：

1. noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返 回客户端错误信息，此 时Redis只响应读操作。
2. volatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直 到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。（常用）



redis阻塞：

​	api或数据结构不合理，slowlog get(n) 命令找到慢查询，	

1）修改为低算法复杂度的命令，如hgetall改为hmget等，禁用keys、sort等命 令

2）调整大对象：缩减大对象数据或把大对象拆分为多个小对象，防止一次命令操作过多的数据

cpu饱和，集群



大key问题：value值过大，hash list set存储过多元素  导致客户端耗时增加，io操作占用cpu，主动删除 被动删除阻塞

解决：bigkeys命令以遍历的方式分析redis中所有的key，并返回每种数据类型top1的key



可删除，使用unlink方式异步删除

不可删除，压缩和拆分



##### redis应用

异步队列：pubish/subscribe

实现延迟队列：使用zset，设置时间戳作为score排序，再通过zrangebyscore查询。



redis事务：提供简单的事务 multi开启事务，exec提交。不支持回滚，回滚会增加很多工作



redis+lua

lua脚本在redis中是原子性的，执行过程中不会插入其他指令。减少网络开销



redis 管道 pipeline

nc指令 节省了rtt（round trip time）将多条命令一起打包，减少了客户端服务端调用次数，减少了上下文切换



redis分布式锁

setnx指令：问题：如果del指令执行异常出错，那么key永远不会释放，，v2：加过期时间，如果expire指令执行异常，那也永远不会释放

原因setnx 和 del指令不是一个原子性的：：解决方案 redission













### mysql

##### mysql调优

第一步对服务器参数调优

通过showprofile命令分析，如果sql语句执行时间长，就需要对mysql服务器的参数进行优化

优化硬件：配置较大的内存，合理分配磁盘io，配置多处理器

优化参数：**linux系统中在/etc/my.cnf中进行配置：**

- innodb_buffer_pool_size：表示缓冲池的大小，缓存索引的数据和表中的数据，该值越大查询速度越快，该值的大小取决于内存的大小。
- key_buffer_size：表示索引缓冲区的大小，该缓冲区所有的线程共享，该值越大代表可以更好的处理索引，该值的大小取决于内存的大小。
- table_cache：表示同时打开的表的个数。
- query_cache_size：表示查询缓冲区的大小，sql语句查询时先到查询缓冲区中进行查询，如果查询缓冲区中没有才会到磁盘中进行获取。该参数需要和query_cache_type配合使用。

第二步：优化表的设计：

表的设计遵循三范式：每一列都是不可分割的原子单元，，非主属性完全依赖于主键，非主属性之间不能有依赖关系

适当利用反范式增加冗余字段，减少关联表查询

优化数据类型：优先选择存储较小的数据类型

- **对整数类型数据进行优化**
  `遇到整数类型的字段可以用INT型。对于非负型的数据（如自增ID、整型IP）来说，要优先使用无符号整型UNSIGNED来存储。`
- **既可以使用文本类型也可以使用整数类型的字段，要选择使用整数类型。**
  `跟文本类型数据相比，大整数往往占用更少的存储空间。`
- **避免使用TEXT、BLOB数据类型**
  `在排序操作时，对于TEXT、BLOB数据类型的数据不能是用内存临时表，必须使用磁盘临时表。还需要进行二次查询进行回表。`
- **避免使用ENUM类型**
  `修改ENUM值需要使用ALTER语句，该类型的ORDER BY操作效率低，需要额外操作，使用TINYINT带代替。`
- **使用TIMESTAMP存储时间**
  `TIMESTAMP占4个字节，DATETIME使用8个字节，同时TIMESTAMP具有自动赋值以及自动更新的特性。`
- **用DECIMAL代替FLOAT和DOUBLE存储精确浮点数**
  `DECIMAL在财务类型的数据下要使用。`

优化查询逻辑：

在被驱动表上的where字段上建立索引，

使用覆盖索引

使用索引下推





##### mvcc多版本并发控制

mvcc解决了脏读幻读不可重复读的问题，保证了事务的隔离性，实现了数据的一致性读

mvcc实现依赖于隐藏字段（trx_id,roll_point），undolog实现了多版本，readview实现了并发控制



快照读：读取数据的历史版本，不加锁的普通select属于快照读，基于mvcc。

当前读：读取的是最新版本的数据，加锁的select，基于锁实现。



trxid每次修改一条记录时，会把该事务的事务id赋值给trxid

rollpoint，每次修改一条记录时，会把旧版本写入undolog日志中，这个隐藏列相当于一个指针。可以通过该隐藏列找到历史版本

readview是事务在使用mvcc机制进行快照读时产生的读视图

- 如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
- 如果被访问版本的trx_id属性值小于ReadView中的up_limit_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。
- 如果被访问版本的trx_id属性值大于或等于ReadView中的low_limit_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。
- 如果被访问版本的trx_id属性值在ReadView的up_limit_id和low_limit_id之间，那就需要判断一下trx_id属性值是不是在trx_ids列表中：
  `如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问。`
  `如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。`

读已提交：每次查询都会生成readview

可重复读：只在第一次查询时生成readview

==mvcc流程==

首先获取事务自身的版本号，事务id————》获取事务的readview————》查询得到的事务id，与readview的规则进行比较————》不符合从undolog版本链中取出下一个版本的数据————》返回符合规则的数据



##### 事务

概念：一组操作将数据从一个状态转换到另一个状态，要么所有的操作执行成功，事务提交，数据永远被修改，要么事务执行失败，事务回滚，数据变为执行前的状态。

四大特性：

atomicity：原子性，由undolog保证，事务是一个不可分割的逻辑操作单元，要么执行成功，要么失败

consistency：一致性，由原子性，隔离性，持久性保证：事务执行前后，数据从一个安全的状态转到另一个安全的状态

isolation：隔离性，由mvcc和锁保证：两个事务执行互不影响

durability：持久性，由redolog保证，事务执行成功，数据的改变就是永久性的。

一些命令：start tranasction，begin，commit，rollback

数据并发问题：

脏读：事务a读取未提交事务b修改过的数据，之后事务b回滚

脏写：事务a修改未提交事务b修改过的数据，事务a提交，之后事务b回滚

不可重复读：事务a读取了一个数据未提交，事务b修改提交，事务a再次读取，数值不同。

幻读：事务a读取了一个字段为null的数据，事务b插入并提交，事务a再次读取有值了。

隔离级别：

读已提交，可重复读，串行化。



##### 锁

事务的隔离性通过锁来保证：

锁分为读锁，写锁。

select。。for share，forupdate

在没有锁的情况下，读写会出现脏读脏写不可重复读等问题。

解决：

快照读：读取数据的历史版本，不加锁的select。由mvcc实现。

当前读：读取数据的最新版本。

方案一：读操作利用mvcc，写操作利用排它锁。

方案二：读操作写操作都加锁。

表级锁：表读锁，表写锁。

意向锁：多粒度锁，允许表级锁和行级锁共存，由存储引擎自己维护，用户不可手动操作。

现在有两个事务，A和B，事务b想要在表级别上加共享锁或排他锁，如果a没有生成意向锁，需要在表的每一页每一行检查是否存在锁，如果生成意向锁，

只需要检查需要加的锁与意向锁是否共存就行。

元数据锁：

当对一个表进行ddl语句时，加元数据写锁，执行dml语句时，加元数据读锁

行级锁：

记录锁，对一条记录进行加锁，读锁写锁

间隙锁，对当前记录和记录前的id之间的范围加锁

临键锁：记录锁和间隙锁的组合：

左开右闭区间，，



乐观锁和悲观锁

乐观锁：cas

悲观锁：synchronized，lock



死锁：

- **两个或多个事务都持有对方需要的锁，但是都不释放，就会导致死锁。**



##### 事务日志

事务的隔离性由锁实现，原子性，一致性，持久性由redolog，undolog保证

redolog：重做日志。

传统的情况下，数据修改后写入bufferpool，如果在写入磁盘之前，服务器出现异常，数据就会丢失，破坏了事务的持久性。

两种方式：1.每次修改数据提交事务前就将数据刷新到磁盘，问题是：innodb是以页作为内存和磁盘交互的基本单元，如果仅仅修改1个字节的数据就将数据页刷新到磁盘，会增加磁盘io时间，造成资源浪费。而且修改一条数据可能会涉及多个页面，这些页面可能不是连续的，需要随机io。

2.采用redolog：每次修改数据后，就记录到redolog，系统重启后，使用redolog重新执行。

优点：减少了磁盘io次数，存储空间小，只存储空间id，页号，偏移量，顺序存储，采用追加写的方式存储，顺序io

redolog分为两部分：redolog buffer（内存），redolog file（磁盘）

刷盘策略：**innodb_flush_log_at_trx_commit**

参数为0：每隔1s将日志写入日志文件，再将日志文件写到磁盘（先写到pagecache中，再将pagecache中的日志写到redolog file）

参数为1：每次提交事务将日志写入日志文件，再将日志文件写到磁盘

参数为2：每次提交事务将日志写入日志文件，每隔1s再将日志文件写到磁盘



刷盘：checkpoint（写入磁盘的位置），writepos（刷新到日志文件的位置）

相当于一个园上的两个点，一旦writepos追上checkpoint，就无法再写入日志。



undolog：事务原子性的保证。在事务中更新数据之前将旧版本的数据写入一个undolog中

1、在事务执行到一半的时候，当出现服务器本身的错误、操作系统错误、断电、程序员手动输入rollback情况时，需要使用undo 日志进行回滚操作，来保证事务的原子性，从逻辑上看该事务什么也没有做。

2.2undo日志中存储了哪些数据

当我们要对一条记录做改动时(这里的改动可以指INSERT、DELETE、UPDATE)需要往redo日志中记录一些数据：undo log的产生会伴随着redo log的产生，这是因为undo log也需要持久性的保护，在 重启之后还可以使用undo log进行回滚操作。

- 你插入了一条记录时，至少要把这条记录的主键值记录下来，之后回滚的时候只需要把这个主键值对应的记录删掉就好了。(对于每个INSERT，lnnoDB存储引擎会完成一个DELETE)
- 你删除了一条记录时，至少要把这条记录中的内容都记录下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了。(对于每个DELETE，InnoDB存储引擎会执行一个INSERT)
- 你更新了一条记录时，至少要把修改这条记录前的旧值都记录下来，这样之后回滚时再把这条记录更新为旧值就好了。(对于每个UPDATE，InnoDB存储引擎会执行一个相反的UPDATE，将修改前的行放回去)

作用：**回滚数据，mvcc**

总结：undolog是物理日志，事务回滚，只是将数据恢复成修改之前的样子

redolog是逻辑日志，记录的是数据页的物理变化，undolog不是redolog的逆过程。





### 微服务

##### 概念

什么是微服务：是一种软件架构风格，将一个大型服务拆分成一个个小型的，自洽且松耦合的服务，每个服务负责特定的业务功能，并通过轻量级通信机制通讯。

每个微服务都可以独立运行部署。增加了灵活性，可伸缩性，可扩展性。

单体化--》服务化--》微服务：单体服务过大--》soa--》微服务，，soa是一种设计原则，微服务可以看作是soa的一种实践。



 问题：系统复杂，服务间通信开销，团队沟通，数据一致性，部署运维复杂



解决方案：dubbo，spring cloud alibaba， spring cloud netflix。

组件：N：enreka consul，springcloud config，feign，zuul gateway hystrix  A：nacos，nacos config，gateway，sentinel，skywalking



##### 注册中心

作用：服务注册（启动时注册到注册中心），服务发现（客户端向注册中心查询可用的服务实例，客户端选择合适的实例进行调用），负载均衡，故障恢复，服务治理

eureka ap consul cp zookeeper cp nacos ap/cp

enreka原理：服务启动后，将实例注册到注册中心，消费者可以查询服务实例列表获取可用的服务实例

服务实例会定期向注册中心server发送心跳，以表示存活，如果一段时间没有接收到服务实例的心跳，将会标记为不可用，踢出服务列表，下线

负载均衡：enreka在调用其他服务时，会从本地缓存中获取服务的注册信息，本地缓存没有，向eureka发送查询请求，获取可用服务实例，通过负载均衡算法选择其中一个调用



保证高可用： 多实例部署：将enreka实例部署在多个节点上，

服务注册消息的复制：当一个服务实例向eureka server注册时，每个eureka server实例都会复制其他实例的注册信息，以保持数据一致性

自我保护机制：当eureka server 节点一段时间没有收到心跳，自动进入自我保护机制，不再剔除注册表中的服务实例，防止网络抖动或其他原因造成的误剔除。



##### 配置中心

作用：对不同环境，不同实例或者在动态运行时实例需要调整和管理

配置中心：springcloud config，nacos consul apollo zookeeper

nacos配置中心原理：配置信息存储--》注册配置信息--》获取配置信息--》监听配置变化

nacos配置中心长轮询机制：客户端发起pull请求，服务端检查配置有没有变更，如果没有，设置一个定时任务，在一段时间后执行，并将客户端加入等待队列。

在等待期间，一旦配置信息发生变更，立即返回结果给客户端，，如果在等待期间，配置没有发生变更，则达到超时时间返回结果给客户端



##### 远程调用

http和rpc，http是应用层协议，主要强调网络通信，rpc是分布式系统之间通信的协议‘

feign基于http，dubbo基于rpc



feign是一个声明式的web服务客户端，简化了使用基于http的远程服务的开发

feign第一次调用耗时很长：主要原因是ribbon的懒加载机制，发生第一次调用时，feign会触发ribbon的加载过程，（从注册中心获取服务列表，建立连接池等操作），增加首次调用耗时

feign实现认证传递：使用拦截器传递认证信息，可以通过实现Requestrceptor接口来定义拦截器，将认证信息加到请求头，然后注册到feign的配置中。

feign的负载均衡是通过集成ribbon实现的，ribbon通过从注册中心获取可用实例列表，并通过负载均衡算法选择合适的服务实例进行请求转发，实现负载均衡。

负载均衡的算法：

轮询：按照顺序将请求分配给后端服务器

加权轮询算法：在轮询的基础上加了权重的概念。

随机算法：随机分配

加权随机：

最少链接：根据后端服务器的连接数

hash算法：



##### 服务容灾

服务雪崩：一个或多个服务出现故障，如果这时候依赖的服务还是不断在请求，那么这些请求的压力会在下游不断堆积，进而导致下游服务负载增加，系统崩溃。

解决：服务高可用部署，限流或熔断，缓存或降级。

服务熔断：当某个服务出现异常或故障时，迅速隔离服务，后续请求返回默认值或错误信息，防止系统崩溃。

服务降级：也是微服务的一种容错机制，用于系统资源紧张或故障时保证核心功能。当系统出现异常时，主动屏蔽一些非核心功能，只提供最基本的功能，以保证系统稳定运行。



熔断降级方案：

hystrix，resilience4J，sentinel，dubbo

hystrix：@HystrixCommand(fallbackMethod = "fallbackMethod")

熔断：通过设置阈值来监控服务的错误率和超时时间，达到阈值熔断器将打开。

降级：当熔断器打开后，hystrix可以提供一个备用的降级方法或返回默认值，以保证系统稳定运行。



sentinel限流：

定义资源：资源可以是url，方法，用于标识需要进行限流的请求

配置限流规则：配置限流阈值，限流模式，资源名称

监控流量：监控每个资源的流量情况

限流控制：超过限流阈值，进行限制，拒绝，或进行其他降级处理。

采用的滑动窗口限流，滑动窗口限流算法是一种基于时间窗口的限流算法。它将一段时间划分为多个时间窗口，并在每个时间窗口内统计请求的数量。通过动态地调整时间窗口的大小和滑动步长，可以更精确地控制请求的通过速率。

Sentinel利用了Token Server和Token Client的机制来实现集群限流。

开启集群限流后，Client向Token Server发送请求，Token Server根据配置的规则决定是否限流



##### 服务网关

api网关：是一种中间层服务器，用于集中管理，保护，路由到后端服务器。充当客户端和后端服务之间的入口点，提供了一组统一的接口来管理和控制api的访问

功能：路由转发，负载均衡，认证与授权，监控与日志，api版本管理，缓存

zuul，gateway，Kong，

spring cloud gateway：

route（路由）：定义请求的匹配规则和转发目标，通过配置路由将请求映射到后端的服务实例或url上。

predicate（断言）：用于匹配请求的条件。如果请求满足断言的条件，则会应用所配置的过滤器。Spring Cloud Gateway提供了多种内置的断言，如Path（路径匹配）、Method（请求方法匹配）、Header（请求头匹配）等，同时也支持自定义断言。

filter（过滤器）：用于对请求进行处理和转换，可以修改请求，响应和执行自定义逻辑



##### 服务监控

prometheus和grafana

Prometheus：是一个开源的监控系统，可以通过http协议定期拉取微服务的·指标数据

grafana：是一个开源的可视化仪表板工具，与Prometheus配合使用

日志收集：

日志收集的方案很多，比如elk

elasticsearch：分布式搜索和分析引擎，用于存储和索引大量的日志数据

logstash：收集，过滤，转发日志数据的工具

kibana：用于日志数据可视化和分析的工具。

es提供日志存储和检索功能，logstash负责将日志收集到es，kibana负责将日志数据可视化分析。

流程：

1.在每个微服务中配置日志输出，将微服务的日志输出到标准输出studio或日志文件

2.使用logstash收集日志：配置logstash收集器，通过配置输入插件监听微服务的日志输出，并进行过滤和处理

3.将日志文件发送到elasticsearch：配置logstash的输出插件，将经过处理的日志数据发送到elasticsearch进行存储和索引

4.使用kibana进行可视化分析，通过Kibana连接到Elasticsearch，创建仪表盘、图表和搜索查询，实时监控和分析微服务的日志数据

除了应用最广泛的ELK，还有一些其它的方案比如`Fluentd`、`Graylog`、`Loki`、`Filebeat`，一些云厂商也提供了付费方案，比如阿里云的`sls`
